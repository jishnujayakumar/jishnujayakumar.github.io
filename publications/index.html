<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Publications | Jishnu Jaykumar Padalunkal</title>
    <meta name="author" content="Jishnu Jaykumar Padalunkal">
    <meta name="description" content="&lt;a href='https://scholar.google.com/citations?user=08esT74AAAAJ&amp;hl=en&amp;&amp;sortby=pubdate' target='_blank'&gt;&lt;b class='google-scholar-link'&gt;Google Scholar&lt;/b&gt;&lt;/a&gt; | * denotes equal contribution and joint lead authorship.">
    <meta name="keywords" content="jishnu jaykumar padalunkal, phd student, utdallas, nvidia, iit-kgp, iisc, iiit vadodara">


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

    <!-- Bootstrap Table -->
    <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css">

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light">

    

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;&lt;/text&gt;&lt;/svg&gt;">
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="/publications/">

    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark">

    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Jishnu </span>Jaykumar Padalunkal</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">About</a>
              </li>
              
              <!-- Blog -->
              <!-- <li class="nav-item ">
                <a class="nav-link" href="/blog/">blog</a>
              </li> -->

              <!-- Other pages -->
              <li class="nav-item active">
                <a class="nav-link" href="/publications/">Publications<span class="sr-only">(current)</span></a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/teaching">Teaching</a>
              </li>
<li class="nav-item">
                <a class="nav-link" href="https://drive.google.com/file/d/1VUsrI9BKeB4lmhxnfEi8CYO9jLzfR5vc" target="_blank">CV</a>
              </li>

              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>

      <!-- Scrolling Progress Bar -->
      <progress id="progress" value="0">
        <div class="progress-container">
          <span class="progress-bar"></span>
        </div>
      </progress>
    </header>


    <!-- Content -->
    <div class="container mt-5">
      
        <!-- page.html -->
        <div class="post">

          <header class="post-header">
            <h1 class="post-title">Publications</h1>
            <p class="post-description"><a href="https://scholar.google.com/citations?user=08esT74AAAAJ&amp;hl=en&amp;&amp;sortby=pubdate" target="_blank"><b class="google-scholar-link">Google Scholar</b></a> | * denotes equal contribution and joint lead authorship.</p>
          </header>

          <article>
            <div class="publications">


  <h2 class="year">2023</h2>
  <h2 class="bibliography">2023</h2>
<ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 preview">
<figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_thumbnails/real-world.gif-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_thumbnails/real-world.gif-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_thumbnails/real-world.gif-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/publication_thumbnails/real-world.gif" class="preview z-depth-1 rounded" width="auto" height="auto" alt="real-world.gif" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>
</div>

        <!-- Entry bib key -->
        <div id="padalunkal2023protoclip" class="col-sm-8">
        <!-- Title -->
        <div class="title">Proto-CLIP: Vision-Language Prototypical Network for Few-Shot Learning</div>
        <!-- Author -->
        <div class="author">
        

        <em>Jishnu Jaykumar P</em>, <a href="https://scholar.google.com/citations?user=wPO_ZgUAAAAJ">Kamalesh Palanisamy</a>, <a href="https://scholar.google.com/citations?user=48Y9F-YAAAAJ">Yu-Wei Chao</a>, <a href="https://scholar.google.com/citations?user=R-lKQqkAAAAJ&amp;hl=en">Xinya Du</a>, and <a href="https://scholar.google.com/citations?user=9cZUlEYAAAAJ">Yu Xiang</a>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>arXiv preprint arXiv:2307.03073</em>, 2023
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Cite</a>
            <a href="https://arxiv.org/pdf/2307.03073.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
            <a href="https://github.com/IRVLUTD/Proto-CLIP" class="btn btn-sm z-depth-0" role="button">Code</a>
            <a href="https://irvlutd.github.io/Proto-CLIP" class="btn btn-sm z-depth-0" role="button">Website</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span>
              <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>We propose a novel framework for few-shot learning by leveraging large-scale vision-language models such as CLIP. Motivated by the unimodal prototypical networks for few-shot learning, we introduce PROTO-CLIP that utilizes image prototypes and text prototypes for few-shot learning. Specifically, PROTO-CLIP adapts the image encoder and text encoder in CLIP in a joint fashion using few-shot examples. The two encoders are used to compute prototypes of image classes for classification. During adaptation, we propose aligning the image and text prototypes of corresponding classes. Such a proposed alignment is beneficial for few-shot classification due to the contributions from both types of prototypes. We demonstrate the effectiveness of our method by conducting experiments on benchmark datasets for few-shot learning as well as in the real world for robot perception.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">padalunkal2023protoclip</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Proto-CLIP: Vision-Language Prototypical Network for Few-Shot Learning}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{P, Jishnu Jaykumar and Palanisamy, Kamalesh and Chao, Yu-Wei and Du, Xinya and Xiang, Yu}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{arXiv preprint arXiv:2307.03073}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 preview">
<figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_thumbnails/scene-replica.webp-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_thumbnails/scene-replica.webp-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_thumbnails/scene-replica.webp-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/publication_thumbnails/scene-replica.webp" class="preview z-depth-1 rounded" width="auto" height="auto" alt="scene-replica.webp" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>
</div>

        <!-- Entry bib key -->
        <div id="khargonkar2023scenereplica" class="col-sm-8">
        <!-- Title -->
        <div class="title">SceneReplica: Benchmarking Real-World Robot Manipulation by Creating Replicable Scenes</div>
        <!-- Author -->
        <div class="author">
        

        <a href="https://kninad.github.io/">Ninad Khargonkar*</a>, <a href="https://labs.utdallas.edu/irvl/people/">Sai Haneesh Allu*</a>, <a href="https://youngsean.github.io/">Yangxiao Lu</a>, <em>Jishnu Jaykumar P</em>, <a href="https://scholar.google.com/citations?user=4yki88YAAAAJ&amp;hl=en">Balakrishnan Prabhakaran</a>, and <a href="https://scholar.google.com/citations?user=9cZUlEYAAAAJ">Yu Xiang</a>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>arXiv preprint arXiv:2306.15620</em>, 2023
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Cite</a>
            <a href="https://arxiv.org/pdf/2306.15620.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
            <a href="https://github.com/IRVLUTD/SceneReplica" class="btn btn-sm z-depth-0" role="button">Code</a>
            <a href="https://irvlutd.github.io/SceneReplica/" class="btn btn-sm z-depth-0" role="button">Website</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span>
              <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>We present a new reproducible benchmark for evaluating robot manipulation in the real world, specifically focusing on the task of pick-and-place. Our benchmark uses the YCB objects, a commonly used dataset in the robotics community, to ensure that our results are comparable to other studies. Additionally, the benchmark is designed to be easily reproducible in the real world, making it accessible for researchers and practitioners. We also provide our experimental results and analyses for model-based and model-free 6D robotic grasping on the benchmark, where representative algorithms for object perception, grasping planning and motion planning are evaluated. We believe that our benchmark will be a valuable tool for advancing the field of robot manipulation. By providing a standardized evaluation framework, researchers can more easily compare different techniques and algorithms, leading to faster progress in developing robot manipulation methods.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">khargonkar2023scenereplica</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{SceneReplica: Benchmarking Real-World Robot Manipulation by Creating Replicable Scenes}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Khargonkar*, Ninad and Allu*, Sai Haneesh and Lu, Yangxiao and P, Jishnu Jaykumar and Prabhakaran, Balakrishnan and Xiang, Yu}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{arXiv preprint arXiv:2306.15620}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 preview">
<figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_thumbnails/fewsol.webp-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_thumbnails/fewsol.webp-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_thumbnails/fewsol.webp-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/publication_thumbnails/fewsol.webp" class="preview z-depth-1 rounded" width="auto" height="auto" alt="fewsol.webp" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>
</div>

        <!-- Entry bib key -->
        <div id="padalunkal2023fewsol" class="col-sm-8">
        <!-- Title -->
        <div class="title">FewSOL: A Dataset for Few-Shot Object Learning in Robotic Environments</div>
        <!-- Author -->
        <div class="author">
        

        <em>Jishnu Jaykumar P</em>, <a href="https://scholar.google.com/citations?user=48Y9F-YAAAAJ">Yu-Wei Chao</a>, and <a href="https://scholar.google.com/citations?user=9cZUlEYAAAAJ">Yu Xiang</a>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In 2023 IEEE International Conference on Robotics and Automation (ICRA)</em>, 2023
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Cite</a>
            <a href="https://arxiv.org/pdf/2207.03333.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
            <a href="https://github.com/IRVLUTD/few-shot-dataset" class="btn btn-sm z-depth-0" role="button">Code</a>
            <a href="/assets/pdf/FewSOL/posters/ICRA2023_FewSOL_Poster.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Poster</a>
            <a href="/assets/pdf/FewSOL/FewSOL-ICRA23-Graphical-Abstract.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Graphical Abstract</a>
            <a href="https://irvlutd.github.io/FewSOL" class="btn btn-sm z-depth-0" role="button">Website</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right" data-doi="10.1109/ICRA48891.2023.10161143"></span>
              <span class="__dimensions_badge_embed__" data-doi="10.1109/ICRA48891.2023.10161143" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>We introduce the Few-Shot Object Learning (FEWSOL) dataset for object recognition with a few images per object. We captured 336 real-world objects with 9 RGB-D images per object from different views. Fewsol has object segmentation masks, poses, and attributes. In addition, synthetic images generated using 330 3D object models are used to augment the dataset. We investigated (i) few-shot object classification and (ii) joint object segmentation and few-shot classification with state-of-the-art methods for few-shot learning and meta-learning using our dataset. The evaluation results show the presence of a large margin to be improved for few-shot object classification in robotic environments, and our dataset can be used to study and enhance few-shot object recognition for robot perception. Dataset and code available at https://irvlutd.github.io/FewSOL.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">padalunkal2023fewsol</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{FewSOL: A Dataset for Few-Shot Object Learning in Robotic Environments}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{P, Jishnu Jaykumar and Chao, Yu-Wei and Xiang, Yu}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2023 IEEE International Conference on Robotics and Automation (ICRA)}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/ICRA48891.2023.10161143}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{9140-9146}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 preview">
<figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_thumbnails/seq-analysis.webp-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_thumbnails/seq-analysis.webp-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_thumbnails/seq-analysis.webp-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/publication_thumbnails/seq-analysis.webp" class="preview z-depth-1 rounded" width="auto" height="auto" alt="seq-analysis.webp" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>
</div>

        <!-- Entry bib key -->
        <div id="chattopadhyay2023sequential" class="col-sm-8">
        <!-- Title -->
        <div class="title">A sequential approach for noninferiority or equivalence of a linear contrast under cost constraints.</div>
        <!-- Author -->
        <div class="author">
        

        <a href="https://scholar.google.com/citations?user=PTS3aeAAAAAJ&amp;hl=en&amp;oi=ao">Bhargab Chattopadhyay</a>, <a href="https://scholar.google.co.in/citations?user=NZjB-lUAAAAJ&amp;hl=en">Tathagata Bandyopadhyay</a>, <a href="https://scholar.google.com/citations?user=G9JORkUAAAAJ&amp;hl=en&amp;oi=ao">Ken Kelley</a>, and Jishnu J Padalunkal</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>Psychological Methods</em>, 2023
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Cite</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right" data-doi="https://doi.org/10.1037/met0000570"></span>
              <span class="__dimensions_badge_embed__" data-doi="https://doi.org/10.1037/met0000570" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Planning an appropriate sample size for a study involves considering several issues. Two important considerations are cost constraints and variability inherent in the population from which data will be sampled. Methodologists have developed sample size planning methods for two or more populations when testing for equivalence or noninferiority/superiority for a linear contrast of population means. Additionally, cost constraints and variance heterogeneity among populations have also been considered. We extend these methods by developing a theory for sequential procedures for testing the equivalence or noninferiority/superiority for a linear contrast of population means under cost constraints, which we prove to effectively utilize the allocated resources. Our method, due to the sequential framework, does not require prespecified values of unknown population variance(s), something that is historically an impediment to designing studies. Importantly, our method does not require an assumption of a specific type of distribution of the data in the relevant population from which the observations are sampled, as we make our developments in a data distribution-free context. We provide an illustrative example to show how the implementation of the proposed approach can be useful in applied research.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">chattopadhyay2023sequential</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A sequential approach for noninferiority or equivalence of a linear contrast under cost constraints.}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Chattopadhyay, Bhargab and Bandyopadhyay, Tathagata and Kelley, Ken and Padalunkal, Jishnu J}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Psychological Methods}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{American Psychological Association}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1037/met0000570}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
</ol>

  <h2 class="year">2021</h2>
  <h2 class="bibliography">2021</h2>
<ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 preview">
<figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_thumbnails/re-embed-kgqa.webp-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_thumbnails/re-embed-kgqa.webp-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_thumbnails/re-embed-kgqa.webp-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/publication_thumbnails/re-embed-kgqa.webp" class="preview z-depth-1 rounded" width="auto" height="auto" alt="re-embed-kgqa.webp" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>
</div>

        <!-- Entry bib key -->
        <div id="P2021" class="col-sm-8">
        <!-- Title -->
        <div class="title">[Re] Improving Multi-hop Question Answering over Knowledge Graphs using Knowledge Base Embeddings</div>
        <!-- Author -->
        <div class="author">
        

        <em>Jishnu Jaykumar P</em>, and <a href="https://scholar.google.co.in/citations?hl=en&amp;user=m2QUCyYAAAAJ">Ashish Sardana</a>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          May 2021
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Cite</a>
            <a href="https://zenodo.org/record/4834942/files/article.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
            <a href="https://github.com/jishnujayakumar/MLRC2020-EmbedKGQA" class="btn btn-sm z-depth-0" role="button">Code</a>
            <a href="https://rescience.github.io/bibliography/P_2021.html" class="btn btn-sm z-depth-0" role="button">Website</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right" data-doi="10.5281/ZENODO.4834942"></span>
              <span class="__dimensions_badge_embed__" data-doi="10.5281/ZENODO.4834942" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Our work consists of four parts: (1) Reproducing results from Saxena et al. [2020] (2) Adding more experiments by
replacing the knowledge graph embedding method (3) and exploring the question embedding method using various
transformer models (4) Verifying the importance of Relation Matching (RM) module. Based on the code shared by
the authors, we have reproduced the results for the EmbedKGQA method. We have not purposely performed relation
matching to validate point-4.
</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">P2021</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{[{Re}] {Improving} {Multi}-hop {Question} {Answering} over {Knowledge} {Graphs} using {Knowledge} {Base} {Embeddings}}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{P, Jishnu Jaykumar and Sardana, Ashish}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{ReScience C}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{ReScience C}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://zenodo.org/record/4834942}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.5281/ZENODO.4834942}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{7}</span><span class="p">,</span>
  <span class="na">issue</span> <span class="p">=</span> <span class="s">{2}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{#15}</span><span class="p">,</span>
  <span class="na">review_url</span> <span class="p">=</span> <span class="s">{https://openreview.net/forum?id=VFAwCMdWY7}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">may</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">type</span> <span class="p">=</span> <span class="s">{Replication}</span><span class="p">,</span>
  <span class="na">language</span> <span class="p">=</span> <span class="s">{Python}</span><span class="p">,</span>
  <span class="na">domain</span> <span class="p">=</span> <span class="s">{ML Reproducibility Challenge 2020}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{knowledge graph, embeddings, multi-hop, question-answering, deep learning}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 preview">
<figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_thumbnails/edge-detect.webp-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_thumbnails/edge-detect.webp-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_thumbnails/edge-detect.webp-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/publication_thumbnails/edge-detect.webp" class="preview z-depth-1 rounded" width="auto" height="auto" alt="edge-detect.webp" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>
</div>

        <!-- Entry bib key -->
        <div id="singh2021edgedetect" class="col-sm-8">
        <!-- Title -->
        <div class="title">Edge-Detect: Edge-Centric Network Intrusion Detection using Deep Neural Network</div>
        <!-- Author -->
        <div class="author">
        

        <a href="https://scholar.google.co.in/citations?hl=en&amp;user=TUX6cg8AAAAJ">Praneet Singh</a>, <em>Jishnu Jaykumar P</em>, <a href="https://in.linkedin.com/in/akhil-pankaj">Akhil Pankaj</a>, and <a href="https://scholar.google.co.in/citations?hl=en&amp;user=EZP8-BMAAAAJ">Reshmi Mitra</a>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In 2021 IEEE 18th Annual Consumer Communications &amp; Networking Conference (CCNC)</em>, May 2021
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Cite</a>
            <a href="https://ieeexplore.ieee.org/document/9369469" class="btn btn-sm z-depth-0" role="button">PDF</a>
            <a href="https://github.com/racsa-lab/Edge-Detect" class="btn btn-sm z-depth-0" role="button">Code</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right" data-doi="10.1109/CCNC49032.2021.9369469"></span>
              <span class="__dimensions_badge_embed__" data-doi="10.1109/CCNC49032.2021.9369469" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Edge nodes are crucial for detection against multitudes of cyber attacks on Internet-of-Things endpoints and is set to become part of a multi-billion industry. The resource constraints in this novel network infrastructure tier constricts the deployment of existing Network Intrusion Detection System with Deep Learning models (DLM). We address this issue by developing a novel light, fast and accurate ‘Edge-Detect’ model, which detects Distributed Denial of Service attack on edge nodes using DLM techniques. Our model can work within resource restrictions i.e. low power, memory and processing capabilities, to produce accurate results at a meaningful pace. It is built by creating layers of Long Short-Term Memory or Gated Recurrent Unit based cells, which are known for their excellent representation of sequential data. We designed a practical data science pipeline with Recurring Neural Network to learn from the network packet behavior in order to identify whether it is normal or attack-oriented. The model evaluation is from deployment on actual edge node represented by Raspberry Pi using current cybersecurity dataset (UNSW2015). Our results demonstrate that in comparison to conventional DLM techniques, our model maintains a high testing accuracy of  99% even with lower resource utilization in terms of cpu and memory. In addition, it is nearly 3 times smaller in size than the state-of-art model and yet requires a much lower testing time.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">singh2021edgedetect</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Singh, Praneet and P, Jishnu Jaykumar and Pankaj, Akhil and Mitra, Reshmi}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2021 IEEE 18th Annual Consumer Communications &amp; Networking Conference (CCNC)}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Edge-Detect: Edge-Centric Network Intrusion Detection using Deep Neural Network}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1-6}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/CCNC49032.2021.9369469}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
</ol>

  <h2 class="year">2018</h2>
  <h2 class="bibliography">2018</h2>
<ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 preview">
<figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_thumbnails/mv-tractus.webp-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_thumbnails/mv-tractus.webp-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_thumbnails/mv-tractus.webp-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/publication_thumbnails/mv-tractus.webp" class="preview z-depth-1 rounded" width="auto" height="auto" alt="mv-tractus.webp" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>
</div>

        <!-- Entry bib key -->
        <div id="p_mvtractus_2018" class="col-sm-8">
        <!-- Title -->
        <div class="title">MV-Tractus: A simple tool to extract motion vectors from H264 encoded video sources</div>
        <!-- Author -->
        <div class="author">
        

        <em>Jishnu P</em>, and <a href="https://scholar.google.co.in/citations?hl=en&amp;user=TUX6cg8AAAAJ">Praneet Singh</a>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          Oct 2018
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="bibtex btn btn-sm z-depth-0" role="button">Cite</a>
            <a href="https://github.com/jishnujayakumar/MV-Tractus" class="btn btn-sm z-depth-0" role="button">Code</a>
            <a href="https://doi.org/10.5281/zenodo.4422613" class="btn btn-sm z-depth-0" role="button">Website</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right" data-doi="10.5281/zenodo.4422613"></span>
              <span class="__dimensions_badge_embed__" data-doi="10.5281/zenodo.4422613" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          <!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@software</span><span class="p">{</span><span class="nl">p_mvtractus_2018</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Zenodo}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{P, Jishnu and Singh, Praneet}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Zenodo}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">oct</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span><span class="p">,</span>
  <span class="na">version</span> <span class="p">=</span> <span class="s">{2.0}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.5281/zenodo.4422613}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 preview">
<figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_thumbnails/va-4-tm.webp-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_thumbnails/va-4-tm.webp-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_thumbnails/va-4-tm.webp-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/publication_thumbnails/va-4-tm.webp" class="preview z-depth-1 rounded" width="auto" height="auto" alt="va-4-tm.webp" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>
</div>

        <!-- Entry bib key -->
        <div id="cyphyss18va" class="col-sm-8">
        <!-- Title -->
        <div class="title">Video Analytics using YOLO and DeepSORT for Traffic Modelling</div>
        <!-- Author -->
        <div class="author">
        

        <a href="https://scholar.google.co.in/citations?user=OftxRCEAAAAJ&amp;hl=en">Raghu Krishnapuram</a>, <a href="https://in.linkedin.com/in/ayush-sawarni">Ayush Sawarni</a>, <a href="https://www.linkedin.com/in/nishalpereira">Nishal Pereira</a>, <em>Jishnu P</em>, <a href="https://scholar.google.co.in/citations?hl=en&amp;user=EjDp6ogAAAAJ">Prajwal Rao</a>, <a href="https://scholar.google.co.in/citations?hl=en&amp;user=TUX6cg8AAAAJ">Praneet Singh</a>, <a href="https://in.linkedin.com/in/abhay-sharma-2b319316">Abhay Sharma</a>, and
          <span class="more-authors" title="click to view 1 more author" onclick="
                var element = $(this);
                element.attr('title', '');
                var more_authors_text = element.text() == '1 more author' ? 'Soma Biswas' : '1 more author';
                var cursorPosition = 0;
                var textAdder = setInterval(function(){
                  element.text(more_authors_text.substring(0, cursorPosition + 1));
                  if (++cursorPosition == more_authors_text.length){
                    clearInterval(textAdder);
                  }
              }, '10');
              ">1 more author</span>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>2nd Cyber-Physical Systems Symposium (CyPhySS), Indian Institute of Science, Bangalore</em>, Oct 2018
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a href="https://drive.google.com/file/d/1lQV1N-gqOIh_1S3yiOnNDjykZOmqLfil" class="btn btn-sm z-depth-0" role="button" target="_blank">Poster</a>
            <a href="http://www.rbccps.org/cyphyss2018/posters-and-demos/" class="btn btn-sm z-depth-0" role="button">Website</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span>
              <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          
        </div>
      </div>
</li>
</ol>


</div>

          </article>

        </div>

      
    </div>

    <!-- Footer -->
<footer class="fixed-bottom">
   <center>
      <div class="container mt-0">
        © Copyright 2024 Jishnu Jaykumar Padalunkal.
        Theme: <a href="https://github.com/alshedivat/al-folio" target="_blank">Al-Folio</a>.

        
        
        Last updated: January 23, 2024.
        
      </div>
    </center>
</footer>



    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js"></script>

  <!-- Bootstrap Table -->
  <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script>

  <!-- Load Common JS -->
  <script src="/assets/js/no_defer.js"></script>
  <script defer src="/assets/js/common.js"></script>
  <script defer src="/assets/js/copy_code.js" type="text/javascript"></script>

    
  <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script>
  <script async src="https://badge.dimensions.ai/badge.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-GDXDM8QC54"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){ window.dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'G-GDXDM8QC54');
  </script>
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": navbarHeight });
    $("progress-container").css({ "padding-top": navbarHeight });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>

  </body>
</html>
