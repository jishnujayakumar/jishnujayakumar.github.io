---
---

@string{aps = {American Physical Society,}}

@article{padalunkal2023protoclip,
    title={Proto-CLIP: Vision-Language Prototypical Network for Few-Shot Learning}, 
    author={Jishnu Jaykumar P and Kamalesh Palanisamy and Yu-Wei Chao and Xinya Du and Yu Xiang},
    journal={arXiv preprint arXiv:2307.03073},
    year={2023},
    bibtex_show={true},
    website={https://irvlutd.github.io/Proto-CLIP},
    code={https://github.com/IRVLUTD/Proto-CLIP},
    preview={real-world.gif},
    pdf = {https://arxiv.org/pdf/2307.03073.pdf},
    abstract = {We propose a novel framework for few-shot learning by leveraging large-scale vision-language models such as CLIP. Motivated by the unimodal prototypical networks for few-shot learning, we introduce PROTO-CLIP that utilizes image prototypes and text prototypes for few-shot learning. Specifically, PROTO-CLIP adapts the image encoder and text encoder in CLIP in a joint fashion using few-shot examples. The two encoders are used to compute prototypes of image classes for classification. During adaptation, we propose aligning the image and text prototypes of corresponding classes. Such a proposed alignment is beneficial for few-shot classification due to the contributions from both types of prototypes. We demonstrate the effectiveness of our method by conducting experiments on benchmark datasets for few-shot learning as well as in the real world for robot perception.}
}

@article{khargonkar2023scenereplica,
  title={SceneReplica: Benchmarking Real-World Robot Manipulation by Creating Reproducible Scenes}, 
  author={Ninad Khargonkar* and Sai Haneesh Allu* and Yangxiao Lu and Jishnu Jaykumar P and Balakrishnan Prabhakaran and Yu Xiang},
  journal={arXiv preprint arXiv:2306.15620},
  year={2023},
  bibtex_show={true},
  website={https://irvlutd.github.io/SceneReplica/},
  code={https://github.com/IRVLUTD/SceneReplica},
  preview={scene-replica.webp},
  pdf = {https://arxiv.org/pdf/2306.15620.pdf},
  abstract = {We present a new reproducible benchmark for evaluating robot manipulation in the real world, specifically focusing on the task of pick-and-place. Our benchmark uses the YCB objects, a commonly used dataset in the robotics community, to ensure that our results are comparable to other studies. Additionally, the benchmark is designed to be easily reproducible in the real world, making it accessible for researchers and practitioners. We also provide our experimental results and analyses for model-based and model-free 6D robotic grasping on the benchmark, where representative algorithms for object perception, grasping planning and motion planning are evaluated. We believe that our benchmark will be a valuable tool for advancing the field of robot manipulation. By providing a standardized evaluation framework, researchers can more easily compare different techniques and algorithms, leading to faster progress in developing robot manipulation methods.}
}


@INPROCEEDINGS{padalunkal2023fewsol,
  title={FewSOL: A Dataset for Few-Shot Object Learning in Robotic Environments}, 
  author={P, Jishnu Jaykumar and Chao, Yu-Wei and Xiang, Yu},
  booktitle={2023 IEEE International Conference on Robotics and Automation (ICRA)}, 
  doi={10.1109/ICRA48891.2023.10161143},
  pages={9140-9146},
  year={2023},
  website = {https://irvlutd.github.io/FewSOL},
  code = {https://github.com/IRVLUTD/few-shot-dataset},
  preview = {fewsol.webp},
  poster = {/assets/pdf/FewSOL/posters/ICRA2023_FewSOL_Poster.pdf},
  graphical_abstract = {/assets/pdf/FewSOL/FewSOL-ICRA23-Graphical-Abstract.pdf},
  pdf = {https://arxiv.org/pdf/2207.03333.pdf},
  bibtex_show={true},
}


@article{chattopadhyay2023sequential,
  abbr={PsyMet},
  title={A sequential approach for noninferiority or equivalence of a linear contrast under cost constraints.},
  author={Chattopadhyay, Bhargab and Bandyopadhyay, Tathagata and Kelley, Ken and Padalunkal, Jishnu J},
  journal={Psychological Methods},
  year={2023},
  publisher={American Psychological Association},
  bibtex_show = {true},
  preview = {seq-analysis.webp},
  doi = {https://doi.org/10.1037/met0000570},
  abstract = {Planning an appropriate sample size for a study involves considering several issues. Two important considerations are cost constraints and variability inherent in the population from which data will be sampled. Methodologists have developed sample size planning methods for two or more populations when testing for equivalence or noninferiority/superiority for a linear contrast of population means. Additionally, cost constraints and variance heterogeneity among populations have also been considered. We extend these methods by developing a theory for sequential procedures for testing the equivalence or noninferiority/superiority for a linear contrast of population means under cost constraints, which we prove to effectively utilize the allocated resources. Our method, due to the sequential framework, does not require prespecified values of unknown population variance(s), something that is historically an impediment to designing studies. Importantly, our method does not require an assumption of a specific type of distribution of the data in the relevant population from which the observations are sampled, as we make our developments in a data distribution-free context. We provide an illustrative example to show how the implementation of the proposed approach can be useful in applied research.}
}

@article{P2021,
	abbr = {ReScience C},
	title = {[{Re}] {Improving} {Multi}-hop {Question} {Answering} over {Knowledge} {Graphs} using {Knowledge} {Base} {Embeddings}},
  abstract={Our work consists of four parts: (1) Reproducing results from Saxena et al. [2020] (2) Adding more experiments by
replacing the knowledge graph embedding method (3) and exploring the question embedding method using various
transformer models (4) Verifying the importance of Relation Matching (RM) module. Based on the code shared by
the authors, we have reproduced the results for the EmbedKGQA method. We have not purposely performed relation
matching to validate point-4.
},
  author = {P, Jishnu Jaykumar and Sardana, Ashish},
  journal = {ReScience C},
  publisher = {ReScience C},
	bibtex_show = {true},
	url = {https://zenodo.org/record/4834942},
	pdf = {https://zenodo.org/record/4834942/files/article.pdf},
	doi = {10.5281/ZENODO.4834942},
	website = {https://rescience.github.io/bibliography/P_2021.html},
	volume = {7},
	issue = {2},
	number = {#15},
	code = {https://github.com/jishnujayakumar/MLRC2020-EmbedKGQA},
  code_swh = {swh:1:dir:c95bc4fec7023c258c7190975279b5baf6ef6725},
  review_url = {https://openreview.net/forum?id=VFAwCMdWY7},
	month = {may},
	year = {2021},
  type = {Replication},
  language = {Python},
  domain = {ML Reproducibility Challenge 2020},
  keywords = {knowledge graph, embeddings, multi-hop, question-answering, deep learning},
  preview = {re-embed-kgqa.webp}
}


@INPROCEEDINGS{singh2021edgedetect,
  abbr={IEEE CCNC},
  author={Singh, Praneet and P, Jishnu Jaykumar and Pankaj, Akhil and Mitra, Reshmi},
  booktitle={2021 IEEE 18th Annual Consumer Communications & Networking Conference (CCNC)}, 
  title={Edge-Detect: Edge-Centric Network Intrusion Detection using Deep Neural Network}, 
  year={2021},
  pages={1-6},
  doi={10.1109/CCNC49032.2021.9369469},
  pdf={https://ieeexplore.ieee.org/document/9369469},
  code={https://github.com/racsa-lab/Edge-Detect},
  preview={edge-detect.webp},
  bibtex_show={true}
  }


@software{p_mvtractus_2018,
  abbr         = {Zenodo},
  title        = {MV-Tractus: A simple tool to extract motion vectors from H264 encoded video sources},
  publisher    = {Zenodo},
  bibtex_show  = {true},
  author       = {Jishnu P and Praneet Singh},
  journal      = {Zenodo},
  month        = {oct},
  year         = {2018},
  version      = {2.0},
  doi          = {10.5281/zenodo.4422613},
  website      = {https://doi.org/10.5281/zenodo.4422613},
  code         = {https://github.com/jishnujayakumar/MV-Tractus},
  preview = {mv-tractus.webp}
}

@article{cyphyss18va,
  title = {Video Analytics using YOLO and DeepSORT for Traffic Modelling},
  author = {Raghu Krishnapuram and Ayush Sawarni and Nishal Pereira and Jishnu P and Prajwal Rao and Praneet Singh and Abhay Sharma and Soma Biswas},
  year = {2018},
  abbr = {CyPhySS},
  website = {http://www.rbccps.org/cyphyss2018/posters-and-demos/},
  poster = {https://drive.google.com/file/d/1lQV1N-gqOIh_1S3yiOnNDjykZOmqLfil},
  journal = {2nd Cyber-Physical Systems Symposium (CyPhySS), Indian Institute of Science, Bangalore},
  preview = {va-4-tm.webp}
}